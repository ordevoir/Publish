
Пусть $(\Omega, \mathcal{F}, P)$ – [[Probability Space|вероятностное пространство]] и $A, B \in \mathcal{F}$ – два [[Event Outcome Trial Experiment|события]]. Если $P(B) > 0$, то **условная вероятность** (*conditional probability*) события $A$ при условии события $B$ определяется как:

$$
P(A \mid B) = \frac{P(A \cap B)}{P(B)}
$$

где $P(A \cap B)$ – [[Intersection of Events|вероятность пересечения]] событий $A$ и $B$, т.е. вероятность того, что и произойдут и событие $A$ и событие $B$.

Условная вероятность $P(A∣B)$ – это вероятность того, что произошло событие $A$, если известно, что произошло событие $B$. 

>[!addition]- Вывод формулы условной вероятности
> Рассмотрим такую конфигурацию событий $A$ и $B$ на пространстве исходов $\Omega$:
> 
> ![[cnd_prb.png]]
> 
> События $A$ и $B$ совместны. Каждый отрезок представляет собой событие, и его мерой  является вероятность. Мерой $\Omega$ является $1$, мерами событий $A$ и $B$ – вероятности $P(A)$ и $P(B)$ соответственно, а мерой совместного события – вероятность $P(A∩B)$. 
> 
> При условии того, что произошло (или произойдет) событие $B$, заведомо известно, что исход $ω$ принадлежит $B$, поэтому пространство возможных исходов сокращается до множества $B$. Тогда и множество благоприятствующих событию $A$ исходов сокращается до $A∩B$. Так как в данных условиях, полным пространством исходов является $B$, необходимо произвести перенормировку, чтобы вероятность $B$ равнялась $1$. Для этого следует масштабировать все меры на
> $$
> k = \frac{1}{P(B)}  
> $$
> Тогда, для того, чтобы получить вероятность того, что исход $ω$ попал в $A∩B$, необходимо масштабировать исходную меру $P(A∩B)$ коэффициентом $k$:
> $$
> P(A∣B)= k·P(A∩B) = \frac{P(A∩B)}{P(B)} 
> $$
> Интуитивно понятно, что чем больше вероятность пересечения $P(A∩B)$, тем больше шансов для события $A$, с другой стороны, чем менее вероятно $B$, тем сильнее повышается вероятность $A$ при условии $B$. В пределе, когда $B→\Omega$, вероятность $P(A∣B)→P(A)$, т.к. $P(B)→1$, т.е. стремится остаться прежней. Чем более невероятным является событие $B$, тем сильнее меняются условия, когда происходит это событие.

Для пары $A,B∈\mathcal{F}$ мы можем также отметить вероятность появления события $B$ при условии события $A$


$$
P(B \mid A) = \frac{P(A \cap B)}{P(A)}
$$

Из чего можно заключить, что 

$$
P(A \mid B)·P(B) = P(B \mid A) · P(A) \;=\; P(A∩B)
$$

Из чего можно получить теорему Байеса:

$$
P(A \mid B) = \frac{P(B \mid A) · P(A)}{P(B)}  
$$

Если события $A$ и $B$ [[Independent and Dependent Events|независимы]], то 

$$
P(A \mid B) = P(A), \quad P(B \mid A) = P(B)
$$

и тогда 

$$
P(A∩B) = P(A)·P(B)
$$

[[Conditional Probabilities of Random Variables|❐]] Условная вероятность случайной величины
