**Перекрестная проверка** (*cross‑validation*) – это метод выборки из семейства [[Sampling Methods|resampling]], используемый для оценки обобщающей способности модели машинного обучения или статистической модели на независимых данных путём многократного разбиения имеющейся [[Statistics|выборки]] на части для обучения и валидации.

>[!addition] Алгоритм k‑fold cross‑validation
> 1. **Разбить** обучающую выборку на $k$ примерно равных по размеру частей (*folds*):
> $$
> D = D_1 \cup D_2 \cup \dots \cup D_k,\quad D_i \cap D_j = \emptyset \ (i \neq j).
> $$
> 2. **Для каждого** фолда $i = 1, \dots, k$:
>    * Использовать все фолды, кроме $D_i$, для **обучения** модели ([[Sampling Methods|resampling]]).
>    * Использовать фолд $D_i$ для **валидации** (оценки) модели, вычислив некоторую метрику ошибки $E_i$ (например, среднеквадратичную ошибку, точность, AUC).
> 3. **Средняя ошибка** по всем фолдам
> $$
> E_\text{CV} = \frac{1}{k}\sum_{i=1}^k E_i
> $$
>    служит оценкой обобщающей способности модели.

При разбиении может производиться стратификация (Stratified k‑fold CV), или же разбиение может повторяться несколько раз (Repeated k‑fold CV). Еще одним частным случаем является разбиение при $k=1$: каждый раз обучаем на $n-1$ объектах и валидируем на одном. Это называется Leave‑One‑Out CV (LOOCV).

[[Sampling Methods|❐]] Методы выборки