
>[!abstract]
>Корреляция и ковариация это статистические меры, используемые для оценки связи (совместной изменчивости) между двумя [[Random Variable|случайными величинами]] . В отличие от ковариации, на корреляцию не влияет изменение масштаба.
# Ковариация

**Ковариация** (*covariance*) или **корреляционный момент** двух [[Random Variable|случайных величин]] (СВ) $X$ и $Y$ определяется как математическое ожидание произведения их отклонений от своих средних значений:

$$
\mathrm{Cov}(X,Y) = \mathbb E[(X - \mathbb E(X))(Y - \mathbb E(Y))]
$$

где $\mathbb E$ – математическое ожидание.

Статистическая оценка ковариации (выборочная ковариация) определяется формулой

$$
\sigma_{XY} = \mathrm{Cov}(X,Y) = \frac{1}{n} \sum_{i=1}^n (x_i - \overline x)(y_i - \overline y) = \frac{1}{n} \sum_{i=1}^n x_i \space y_i - \overline x \space \overline y
$$
где $\overline x$ и $\overline y$ – средние значения.


>[!Addition] Дисперсия как частный случай ковариации
>Заметим, что ковариация случайной величины с самой собой есть [[_Measures#Статистическая оценка дисперсии|дисперсия]]:
>$$
>\mathrm{Cov}(X,X) = \frac{1}{n} \sum_{i=1}^n (x_i - \overline x)^2 = \sigma_X^2 = \sigma_{XX}
>$$
По аналогии с несмещенной дисперсией, можно рассматривать несмещенную ковариацию, где вместо множителя $(1/n)$ используется $\frac{1}{n-1}$

По абсолютному значению ковариации нельзя судить о том, насколько сильно величины взаимосвязаны, так как масштаб ковариации зависит от их дисперсий. 

>[!example]-
>Пример вычисления ковариации в файле [[RV_Cov_Corr.ipynb]]

# Корреляция

**Линейный коэффициент корреляции** или **коэффициентом Пирсона** (*Pearson Correlation Coefficient* (**PCC**)) представляет собой нормализованную ковариацию:

$$
\mathbf r_{XY} = \frac {\sigma_{XY}}{\sigma_X \sigma_Y}
$$
где $\sigma_{XY}$ – ковариация между случайными величинами $X$ и $Y$, а $\sigma_{X}$ и $\sigma_{Y}$ – их [[_Measures#Стандартное отклонение|стандартные отклонения]].

Коэффициент корреляции не зависит от масштаба, является безразмерной величиной и область значений принадлежит отрезку $[-1, 1]$, при этом 

- $r_{XY} = 1$ – идеальная положительная линейная связь.
- $r_{XY} = -1$ – идеальная отрицательная линейная связь.
- $r_{XY} = 0$ – отсутствие линейной связи.

Статистическая оценка линейного коэффициента корреляции:

$$
\mathbf r_{XY} = \frac{\sum_{i=1}^n (x_i - \overline x)(y_i - \overline y)}{\sqrt{\sum_{i=1}^n (x_i - \overline x)^2 \cdot \sum_{i=1}^n (y_i - \overline y)^2}}
$$

>[!example]-
>Пример вычисления ковариации в файле [[RV_Cov_Corr.ipynb]]

# Матрица разброса

Пусть $\mathbf X$ – матрица $n \times d$ строки которой представляют $n$ объектов, описываемые $d$ признаками. Вектор $\mathbf x_r$ обозначает $r$-ую строку $\mathbf X$, вектор $\mathbf x_c$ – $c$-ую колонку, а $x_{rc}$ – элемент на пересечении $r$-ой строки и $c$-ой колонки. Каждую колонку этой матрицы можно рассматривать как набор выборку некоторой случайной величины.

Обозначим через $\mu_j$ среднее по $j$-ой колонке, а через $\mu^{\mathbf T}$ – вектор-строку длины $d$, содержащую средние $\mu_j$ по всем колонкам:
 
$$
\mu_j = \frac{1}{n} \sum_{i=1}^n \mathbf x_{ij}, \qquad \mu^{\mathbf T} = (\mu_1, \ldots, \mu_d)
$$

Если $\mathbf 1$ – $n$-мерный вектор, содержащий только единицы, то $\mathbf 1 \mu^{\mathrm T}$ – матрица размерности $n \times d$, каждая строкам которой представляет собой векторы $\mu^{\mathrm T}$. Матрица $\mathbf X'=\mathbf X-\mathbf 1 \mu^{\mathrm T}$ называется **центрированной матрицей** (*zero centered*).

**Матрицей разброса** (*scatter matrix*) называется матрица $\mathbf S$ размерности $d \times d$

$$
\mathbf S = \mathbf X'^{\mathrm T} \mathbf X'= \mathbf X^{\mathrm T} \mathbf X - n \mathbf M
$$

где $\mathbf M = \mu \mu^{\mathrm T}$ – матрица $d \times d$ элементами которой являются произведения средних по столбцам $m_{ij} = \mu_i \mu_j$.

Статистическая оценка элементов матрицы разброса 

$$
s_{ij} = \sum_{k=1}^n (x_{ki} - \mu_{i})(x_{kj} - \mu_j)
$$
Если поделить матрицу разброса на $n$, получим ковариационную матрицу.
