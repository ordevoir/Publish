
Статистический смысл [[Sum and Difference of RVs|суммы]]

$$
S_n= \sum_{i=1}^{n} X_i
$$

[[Independent and Dependent Random Variables|взаимно независимых]] случайных величин $X_1, X_2,\ldots, X_n$ в следующем. Предположим, что мы имеем большие выборки для каждой случайной величины $X_1, X_2,\ldots, X_n$. Выберем случайно по одному образцу из каждой выборки, получим набор $x_1^{(1)}, x_2^{(1)}, \ldots, x_n^{(1)}$. Если взять сумму от этих величин, получим одну [[Random Variable|реализацию]] $s_n^{(1)}$ случайной величины $S_n$:

$$
s_n^{(1)} = \sum_{i=1}^n  x_i^{(1)}
$$

Если повторить это $m$ раз, сформируется набор из $m$ реализаций

$$
\bigl\{s_n^{\,(1)},\,s_n^{\,(2)},\,\dots,\,s_n^{\,(m)}\bigr\}
$$

который будет **эмпирической выборкой** случайной величины $S_n$.

Если в случайных величинах имеется зависимость, то это должно учитываться при генерации совместной выборки $x_1^{(1)}, x_2^{(1)}, \ldots, x_n^{(1)}$.

Статистический смысл [[Mean of Several RVs|среднего]]

$$
X_{n}= \frac{1}{n} \sum_{i=1}^{n} X_i
$$

определяется таким же образом, но вместо суммы от выборки $x_1^{(1)}, x_2^{(1)}, \ldots, x_n^{(1)}$ берется их среднее:

$$
\bar x_n^{(1)} = \frac{1}{n} \sum_{i=1}^n  x_i^{(1)}
$$

